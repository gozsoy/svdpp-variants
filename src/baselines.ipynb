{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVERT THIS NB TO PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r_/jwmzgr6s6_762bz0h7x_qll40000gn/T/ipykernel_64066/2139430656.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  ratings_df = pd.read_csv('../data/ratings.dat',sep=\"::\",header=None)\n"
     ]
    }
   ],
   "source": [
    "# read MovieLens 1M dataset\n",
    "ratings_df = pd.read_csv('../data/ratings.dat',sep=\"::\",header=None)\n",
    "\n",
    "# rename columns\n",
    "ratings_df = ratings_df[[0,1,2]].rename(columns={0:'user_id',1:'movie_id',2:'rating'})\n",
    "\n",
    "# split into train, valid and test sets\n",
    "test_size, valid_size = 0.1, 0.1\n",
    "test_split_random_state, valid_split_random_state= 42, 0 \n",
    "train_valid_df, test_df = train_test_split(ratings_df, test_size=test_size, random_state=test_split_random_state)\n",
    "train_df, valid_df = train_test_split(train_valid_df, test_size=valid_size, random_state=valid_split_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance metric root mean squared error\n",
    "rmse = lambda y_true,y_pred: np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 1: predict all ratings '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2593597352393096"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dummy = np.ones((len(test_df.rating.values))) * 3\n",
    "y_true = test_df.rating.values\n",
    "rmse(y_true,y_pred_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 2: predict all ratings train_df's mean rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1164773790818092"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dummy = np.ones((len(test_df.rating.values))) * np.mean(train_valid_df.rating)\n",
    "y_true = test_df.rating.values\n",
    "rmse(y_true,y_pred_dummy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 3: predict user mean rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 4: predict item mean rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CF_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        # pd -> np\n",
    "        self.df = df.values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        item = self.df[idx]\n",
    "        u_id, m_id, r = item[0],item[1],item[2]\n",
    "\n",
    "        return (u_id,m_id),r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegularizedSVD(torch.nn.Module):\n",
    "  def __init__(self, num_users, num_items, global_mean, embedding_dim):\n",
    "    super().__init__()\n",
    "    self.gm = global_mean\n",
    "\n",
    "    # cfg should handle these num_users, num_movies, embedding_dim\n",
    "    self.P = torch.nn.Embedding(num_users, embedding_dim)\n",
    "    self.Q = torch.nn.Embedding(num_items, embedding_dim)\n",
    "    self.B_U = torch.nn.Embedding(num_users, 1)\n",
    "    self.B_I = torch.nn.Embedding(num_items, 1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \n",
    "    # user and item indices start with 1 in dataset, embedding index starts with 0 \n",
    "    # so embedding of user 1 is stored at self.p(0)\n",
    "    user_id, item_id = x[0]-1, x[1]-1\n",
    "\n",
    "    p_u = self.P(user_id)\n",
    "    q_i = self.Q(item_id)\n",
    "    b_u = self.B_U(user_id)\n",
    "    b_i = self.B_I(item_id)\n",
    "\n",
    "    pred_r_ui = torch.sum(p_u * q_i, axis=1) + torch.squeeze(b_u) + torch.squeeze(b_i) + self.gm\n",
    "\n",
    "    return pred_r_ui\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [03:29<00:00, 120.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 / 20, train_loss: 63.9363, train_rmse: 7.8331, val_rmse: 5.8226\n",
      "\n",
      "epoch: 2 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [03:13<00:00, 130.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2 / 20, train_loss: 15.6667, train_rmse: 3.8696, val_rmse: 3.6601\n",
      "\n",
      "epoch: 3 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:23<00:00, 175.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3 / 20, train_loss: 4.6128, train_rmse: 2.0988, val_rmse: 2.7163\n",
      "\n",
      "epoch: 4 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:12<00:00, 191.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4 / 20, train_loss: 1.9999, train_rmse: 1.3846, val_rmse: 2.2975\n",
      "\n",
      "epoch: 5 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:12<00:00, 191.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5 / 20, train_loss: 1.2404, train_rmse: 1.0962, val_rmse: 2.0870\n",
      "\n",
      "epoch: 6 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:33<00:00, 164.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6 / 20, train_loss: 0.9778, train_rmse: 0.9767, val_rmse: 1.9670\n",
      "\n",
      "epoch: 7 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:25<00:00, 174.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7 / 20, train_loss: 0.8560, train_rmse: 0.9147, val_rmse: 1.8852\n",
      "\n",
      "epoch: 8 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:33<00:00, 164.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8 / 20, train_loss: 0.7827, train_rmse: 0.8747, val_rmse: 1.8272\n",
      "\n",
      "epoch: 9 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:13<00:00, 189.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9 / 20, train_loss: 0.7260, train_rmse: 0.8422, val_rmse: 1.7819\n",
      "\n",
      "epoch: 10 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:07<00:00, 198.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10 / 20, train_loss: 0.6812, train_rmse: 0.8158, val_rmse: 1.7405\n",
      "\n",
      "epoch: 11 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:07<00:00, 199.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11 / 20, train_loss: 0.6413, train_rmse: 0.7915, val_rmse: 1.7045\n",
      "\n",
      "epoch: 12 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:12<00:00, 191.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12 / 20, train_loss: 0.6066, train_rmse: 0.7695, val_rmse: 1.6694\n",
      "\n",
      "epoch: 13 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:53<00:00, 145.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13 / 20, train_loss: 0.5785, train_rmse: 0.7511, val_rmse: 1.6470\n",
      "\n",
      "epoch: 14 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:52<00:00, 146.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14 / 20, train_loss: 0.5490, train_rmse: 0.7318, val_rmse: 1.6245\n",
      "\n",
      "epoch: 15 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [02:32<00:00, 166.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15 / 20, train_loss: 0.5264, train_rmse: 0.7164, val_rmse: 1.5981\n",
      "\n",
      "epoch: 16 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25318/25318 [03:04<00:00, 137.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16 / 20, train_loss: 0.5047, train_rmse: 0.7013, val_rmse: 1.5790\n",
      "\n",
      "epoch: 17 / 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14235/25318 [02:04<01:36, 114.33it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb#ch0000031?line=54'>55</a>\u001b[0m     \u001b[39m# save batch metrics\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb#ch0000031?line=55'>56</a>\u001b[0m     batch_train_loss_array\u001b[39m.\u001b[39mappend(loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mitem())\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb#ch0000031?line=56'>57</a>\u001b[0m     batch_train_rmse_array\u001b[39m.\u001b[39mappend(rmse(y_true, y_pred\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb#ch0000031?line=58'>59</a>\u001b[0m \u001b[39m# validation\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb#ch0000031?line=59'>60</a>\u001b[0m model\u001b[39m.\u001b[39meval()\n",
      "\u001b[1;32m/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb Cell 4'\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/gokberk/Desktop/self-projects/svdpp-variants/src/experiments.ipynb#ch0000045?line=0'>1</a>\u001b[0m rmse \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m y_true,y_pred: np\u001b[39m.\u001b[39msqrt(mean_squared_error(y_true, y_pred))\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py:438\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=377'>378</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean_squared_error\u001b[39m(\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=378'>379</a>\u001b[0m     y_true, y_pred, \u001b[39m*\u001b[39m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, multioutput\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39muniform_average\u001b[39m\u001b[39m\"\u001b[39m, squared\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=379'>380</a>\u001b[0m ):\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=380'>381</a>\u001b[0m     \u001b[39m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=381'>382</a>\u001b[0m \n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=382'>383</a>\u001b[0m \u001b[39m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=435'>436</a>\u001b[0m \u001b[39m    0.825...\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=436'>437</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=437'>438</a>\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=438'>439</a>\u001b[0m         y_true, y_pred, multioutput\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=439'>440</a>\u001b[0m     )\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=440'>441</a>\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=441'>442</a>\u001b[0m     output_errors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39maverage((y_true \u001b[39m-\u001b[39m y_pred) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, weights\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py:95\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=60'>61</a>\u001b[0m \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=61'>62</a>\u001b[0m \n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=62'>63</a>\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=91'>92</a>\u001b[0m \u001b[39m    the dtype argument passed to check_array.\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=92'>93</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=93'>94</a>\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m---> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=94'>95</a>\u001b[0m y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=95'>96</a>\u001b[0m y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/metrics/_regression.py?line=97'>98</a>\u001b[0m \u001b[39mif\u001b[39;00m y_true\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=793'>794</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=794'>795</a>\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=795'>796</a>\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=796'>797</a>\u001b[0m         )\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=798'>799</a>\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=799'>800</a>\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=801'>802</a>\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=802'>803</a>\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py:103\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=97'>98</a>\u001b[0m \u001b[39m# First try an O(n) time, O(1) space solution for the common case that\u001b[39;00m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=98'>99</a>\u001b[0m \u001b[39m# everything is finite; fall back to O(n) space np.isfinite to prevent\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=99'>100</a>\u001b[0m \u001b[39m# false positives from overflow in sum method. The sum is also calculated\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=100'>101</a>\u001b[0m \u001b[39m# safely to reduce dtype induced overflows.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=101'>102</a>\u001b[0m is_float \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mfc\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=102'>103</a>\u001b[0m \u001b[39mif\u001b[39;00m is_float \u001b[39mand\u001b[39;00m (np\u001b[39m.\u001b[39misfinite(_safe_accumulator_op(np\u001b[39m.\u001b[39;49msum, X))):\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=103'>104</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/validation.py?line=104'>105</a>\u001b[0m \u001b[39melif\u001b[39;00m is_float:\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py:893\u001b[0m, in \u001b[0;36m_safe_accumulator_op\u001b[0;34m(op, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=869'>870</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=870'>871</a>\u001b[0m \u001b[39mThis function provides numpy accumulator functions with a float64 dtype\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=871'>872</a>\u001b[0m \u001b[39mwhen used on a floating point input. This prevents accumulator overflow on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=889'>890</a>\u001b[0m \u001b[39m    The output of the accumulator function passed to this function.\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=890'>891</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=891'>892</a>\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39missubdtype(x\u001b[39m.\u001b[39mdtype, np\u001b[39m.\u001b[39mfloating) \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mitemsize \u001b[39m<\u001b[39m \u001b[39m8\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=892'>893</a>\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mfloat64)\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=893'>894</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/sklearn/utils/extmath.py?line=894'>895</a>\u001b[0m     result \u001b[39m=\u001b[39m op(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py:2259\u001b[0m, in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=2255'>2256</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m out\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=2256'>2257</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m res\n\u001b[0;32m-> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=2258'>2259</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49madd, \u001b[39m'\u001b[39;49m\u001b[39msum\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, dtype, out, keepdims\u001b[39m=\u001b[39;49mkeepdims,\n\u001b[1;32m   <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=2259'>2260</a>\u001b[0m                       initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[0;32m~/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=82'>83</a>\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=83'>84</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[0;32m---> <a href='file:///Users/gokberk/miniconda3/envs/torch_tf_learning/lib/python3.9/site-packages/numpy/core/fromnumeric.py?line=85'>86</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39;49mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpasskwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_dataset = CF_Dataset(train_df)\n",
    "valid_dataset = CF_Dataset(valid_df)\n",
    "test_dataset = CF_Dataset(test_df)\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=32,shuffle=True)\n",
    "valid_dataloader = torch.utils.data.DataLoader(dataset=valid_dataset,batch_size=32)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=32)\n",
    "\n",
    "\n",
    "global_mean = np.mean(train_df.rating.values)\n",
    "model = RegularizedSVD(num_users=6040, num_items=3952, global_mean=global_mean, embedding_dim=100)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "lowest_val_loss = float('inf')\n",
    "\n",
    "# zero the parameters' gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "epochs = 20\n",
    "beta = 3e-5  # weight decay\n",
    "\n",
    "for epoch in range(epochs):  # loop over dataset\n",
    "\n",
    "    print(f'epoch: {epoch+1} / {epochs}')\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "    \n",
    "    batch_train_loss_array=[]\n",
    "    batch_train_rmse_array=[]\n",
    "    batch_train_reg_loss_array=[] # temporary\n",
    "\n",
    "    for batch_idx, batch_data in enumerate(train_dataloader): # loop over train batches\n",
    "        \n",
    "        #batch_data = batch_data.to(device)\n",
    "        x, y_true = batch_data[0], batch_data[1]\n",
    "        y_true = y_true.to(torch.float32)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # compute loss\n",
    "        mse_loss = loss_fn(y_true,y_pred)\n",
    "\n",
    "        reg_loss = 0\n",
    "        for param in model.parameters():\n",
    "            reg_loss += torch.norm(param,'fro')**2\n",
    "        \n",
    "        loss = mse_loss + beta * reg_loss\n",
    "\n",
    "        # backpropagation\n",
    "        loss.backward()\n",
    "\n",
    "        # gradient descent with optimizer\n",
    "        optimizer.step()\n",
    "            \n",
    "        # save batch metrics\n",
    "        batch_train_loss_array.append(mse_loss.detach().cpu().item())\n",
    "        batch_train_rmse_array.append(rmse(y_true, y_pred.detach().cpu()))\n",
    "        batch_train_reg_loss_array.append(reg_loss.detach().cpu().item()) # temporary\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        batch_valid_rmse_array=[]\n",
    "        \n",
    "        for _, valid_batch_data in enumerate(valid_dataloader): # loop over valid batches\n",
    "            \n",
    "            #valid_batch_data = valid_batch_data.to(device)\n",
    "            valid_x, valid_y_true = valid_batch_data[0], valid_batch_data[1]\n",
    "            valid_y_true = valid_y_true.to(torch.float32)\n",
    "\n",
    "            # forward pass\n",
    "            valid_y_pred = model(valid_x)\n",
    "\n",
    "            # save batch metrics\n",
    "            batch_valid_rmse_array.append(rmse(valid_y_true, valid_y_pred.detach().cpu()))\n",
    "\n",
    "\n",
    "    # display metrics at end of epoch\n",
    "    epoch_train_loss, epoch_train_rmse = np.mean(batch_train_loss_array), np.mean(batch_train_rmse_array)\n",
    "    epoch_val_rmse = np.mean(batch_valid_rmse_array)\n",
    "\n",
    "    print(f'epoch: {epoch+1} / {epochs}, train_loss: {epoch_train_loss:.4f}, train_rmse: {epoch_train_rmse:.4f}, val_rmse: {epoch_val_rmse:.4f}\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a73d1662bd3aab4de55a1a51be85519c6e25d5d617da76d142a49d5ef38ee143"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('torch_tf_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
